{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main_debug.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "rPpZmbiidgtZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Main Debug Notebook"
      ]
    },
    {
      "metadata": {
        "id": "ajbA42EhXNtq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### download weight and libraries\n"
      ]
    },
    {
      "metadata": {
        "id": "eQa8yTQ1A70q",
        "colab_type": "code",
        "outputId": "31dfc190-cc09-47d7-9faf-3b0818ea3019",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "weight_folder = './data/'\n",
        "lib_folder = './src/'\n",
        "img_folder = './img/'\n",
        "if not os.path.exists(weight_folder): \n",
        "  os.mkdir(weight_folder)\n",
        "if not os.path.exists(img_folder): \n",
        "  os.mkdir(img_folder)\n",
        "if not os.path.exists(lib_folder): \n",
        "  os.mkdir(lib_folder)\n",
        "\n",
        "# Download weight\n",
        "weight_url = 'http://www.vlfeat.org/matconvnet/models/imagenet-vgg-verydeep-19.mat'\n",
        "weight_path = weight_folder + 'imagenet-vgg-verydeep-19.mat'\n",
        "if not os.path.exists(weight_path):\n",
        "  !curl -o $weight_path $weight_url\n",
        "\n",
        "# Download libraries\n",
        "libraries = ['vgg.py', 'constants.py', 'neural_network.py', 'utils.py']\n",
        "library_url = 'https://raw.githubusercontent.com/abx67/AdvML-style-transfer/master/src/'\n",
        "\n",
        "for lib in libraries:\n",
        "  lib_path = lib_folder + lib\n",
        "  lib_url = library_url + lib\n",
        "  if not os.path.exists(lib_path):\n",
        "    !curl -o $lib_path $lib_url\n",
        "    \n",
        "# Download images\n",
        "style_img_name = 'van_gogh.jpg'\n",
        "content_img_name = 'new_york.jpg'\n",
        "img_url = 'https://raw.githubusercontent.com/abx67/AdvML-style-transfer/master/img/'\n",
        "\n",
        "style_path = img_folder + style_img_name\n",
        "style_url = img_url + style_img_name\n",
        "content_path = img_folder + content_img_name\n",
        "content_url = img_url + content_img_name\n",
        "\n",
        "if not os.path.exists(style_path):\n",
        "  !curl -o $style_path $style_url\n",
        "if not os.path.exists(content_path):\n",
        "  !curl -o $content_path $content_url"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  510M  100  510M    0     0   108M      0  0:00:04  0:00:04 --:--:--  108M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  2470  100  2470    0     0  14529      0 --:--:-- --:--:-- --:--:-- 14529\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   779  100   779    0     0   5025      0 --:--:-- --:--:-- --:--:--  5025\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  7101  100  7101    0     0  46411      0 --:--:-- --:--:-- --:--:-- 46411\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   674  100   674    0     0   2892      0 --:--:-- --:--:-- --:--:--  2880\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  104k  100  104k    0     0   554k      0 --:--:-- --:--:-- --:--:--  554k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  120k  100  120k    0     0   689k      0 --:--:-- --:--:-- --:--:--  689k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "S8hpK52gbU9O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### import modules"
      ]
    },
    {
      "metadata": {
        "id": "WyJAmez0bZQ7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "import sys\n",
        "sys.path.append(lib_folder)\n",
        "# from neural_network import NeuralNetwork\n",
        "from vgg import VGG"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oHBKl9yxb1pd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### contents definition"
      ]
    },
    {
      "metadata": {
        "id": "5BPKDOEcb4Am",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "VGG_MAT_PATH = weight_path\n",
        "CONTENT_IMAGE_PATH = content_path\n",
        "STYLE_IMAGE_PATH = style_path\n",
        "MIXED_IMAGE_PATH = './output/'\n",
        "if not os.path.exists(MIXED_IMAGE_PATH): \n",
        "  os.mkdir(MIXED_IMAGE_PATH)\n",
        "\n",
        "CONTENT_WEIGHT = 5\n",
        "STYLE_WEIGHT = 500\n",
        "VARIATION_WEIGHT = 100\n",
        "LEARNING_RATE = 10\n",
        "BETA1 = 0.9\n",
        "BETA2 = 0.999\n",
        "EPSILON = 1e-08\n",
        "MAX_ITERATION = 10\n",
        "POOLING = 'max'\n",
        "CHECK_POINT = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P7g6A46QcMfd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### function definition"
      ]
    },
    {
      "metadata": {
        "id": "w9Fs1kUkcLbj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_image(file_path, max_size=None, shape=None):\n",
        "    # load image and define the factor used to tranfer the image size\n",
        "    image = PIL.Image.open(file_path)\n",
        "    # resize by max_size\n",
        "    if max_size is not None:\n",
        "        factor = float(max_size) / np.max(image.size)  # image.size = [height, width, 3]\n",
        "        size = np.array(image.size) * factor\n",
        "        size = size.astype(int)\n",
        "        image = image.resize(size, PIL.Image.LANCZOS)  # image resize with filter LANCZOS\n",
        "    # resize with shape\n",
        "    if shape is not None:\n",
        "        image = image.resize(shape, PIL.Image.LANCZOS)\n",
        "    # return image values with float data type\n",
        "    return np.float32(image)\n",
        "\n",
        "\n",
        "def save_image(file_path, image):\n",
        "    # ensure the pixel value is int between 0 and 255\n",
        "    image = np.clip(image, 0.0, 255.0).astype(np.uint8)\n",
        "    # write to file\n",
        "    PIL.Image.fromarray(image).save(file_path)\n",
        "    return\n",
        "\n",
        "\n",
        "def style_transfer(content_image_path, style_image_path, mixed_image_path,\n",
        "                   content_weight, style_weight, variation_weight,\n",
        "                   pooling, learning_rate, beta1, beta2, epsilon, max_iteration, check_point):\n",
        "    # set the time point\n",
        "    time_start = time.time()\n",
        "\n",
        "    # load image\n",
        "    content_image = load_image(content_image_path)\n",
        "    style_image = load_image(style_image_path, shape=content_image.shape[:2])\n",
        "\n",
        "    # initialize object\n",
        "    vgg = VGG(VGG_MAT_PATH, pooling)\n",
        "    nn = NeuralNetwork(content_image, style_image, vgg, content_weight, style_weight, variation_weight)\n",
        "\n",
        "    # train the model\n",
        "    for i, mixed_image in nn.train_model(learning_rate, beta1, beta2, epsilon, max_iteration, check_point):\n",
        "        save_image(mixed_image_path + 'v1_{}.jpeg'.format(i + 1), mixed_image)\n",
        "\n",
        "    # print time\n",
        "    time_end = time.time()\n",
        "    print('Time elapsed: {} seconds'.format(round(time_end - time_start)))\n",
        "\n",
        "    return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3ioabxYdX8y9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from functools import reduce\n",
        "\n",
        "PATH = '../'\n",
        "\n",
        "CONTENT_LAYER_WEIGHTS = {\n",
        "    'relu4_2': 1.0,\n",
        "}\n",
        "\n",
        "STYLE_LAYER_WEIGHTS = {\n",
        "    'relu1_1': 0.2,\n",
        "    'relu2_1': 0.2,\n",
        "    'relu3_1': 0.2,\n",
        "    'relu4_1': 0.2,\n",
        "    'relu5_1': 0.2,\n",
        "}\n",
        "\n",
        "\n",
        "class NeuralNetwork(object):\n",
        "    # neural network used for style transfer, which includes the definition of loss function, optimization function, etc.\n",
        "    def __init__(self, content, style, vgg, content_weight, style_weight, variation_weight):\n",
        "        # content - image, shape = (height, width, 3)\n",
        "        # style - image, shape = (height, width, 3)\n",
        "        # vgg - vgg object, definition see vgg.py\n",
        "        # content_weight - scalar, weight for the loss of the content image\n",
        "        # style_weight - scalar, weight for the loss of the style image\n",
        "        # variation_weight - scalar, weight for the loss of variation of the mixed image\n",
        "\n",
        "        self.content = content\n",
        "        self.style = style\n",
        "        self.vgg = vgg\n",
        "\n",
        "        self.content_weight = content_weight\n",
        "        self.style_weight = style_weight\n",
        "        self.variation_weight = variation_weight\n",
        "\n",
        "        self.content_shape = (1,) + self.content.shape\n",
        "        self.style_shape = (1,) + self.style.shape\n",
        "\n",
        "        self.content_layer_weights = CONTENT_LAYER_WEIGHTS\n",
        "        self.style_layer_weights = STYLE_LAYER_WEIGHTS\n",
        "\n",
        "        self.content_features = self.get_content_features()\n",
        "        self.style_features = self.get_style_features()\n",
        "\n",
        "        return\n",
        "\n",
        "    def get_content_features(self):\n",
        "        content_features = {}\n",
        "        graph = tf.Graph()\n",
        "        with graph.as_default(), graph.device('/cpu:0'), tf.Session() as sess:\n",
        "            image = tf.placeholder('float', shape=self.content_shape)\n",
        "            net = self.vgg.load_net(image)\n",
        "            content = np.array(self.content - self.vgg.mean_pix)  # de-mean\n",
        "            content = np.reshape(content, (1,) + content.shape)\n",
        "            for layer_name in self.content_layer_weights:\n",
        "                content_features[layer_name] = net[layer_name].eval(feed_dict={image: content})\n",
        "        print(content_features['relu4_2'].shape)\n",
        "        return content_features\n",
        "\n",
        "    def get_style_features(self):\n",
        "        style_features = {}\n",
        "        graph = tf.Graph()\n",
        "        with graph.as_default(), graph.device('/cpu:0'), tf.Session() as sess:\n",
        "            image = tf.placeholder('float', shape=self.style_shape)\n",
        "            net = self.vgg.load_net(image)\n",
        "            style = np.array(self.style - self.vgg.mean_pix)  # de-mean\n",
        "            style = np.reshape(style, (1,) + style.shape)\n",
        "            for layer_name in self.style_layer_weights:\n",
        "                features = net[layer_name].eval(feed_dict={image: style})\n",
        "                features = np.reshape(features, (-1, features.shape[3]))\n",
        "                gram = features.T.dot(features) / features.size  # TODO: find out why divide by the size\n",
        "                style_features[layer_name] = gram\n",
        "        return style_features\n",
        "\n",
        "    def train_model(self, learning_rate, beta1, beta2, epsilon, max_iteration, check_point, init_image='content'):\n",
        "        with tf.Graph().as_default():\n",
        "            # initial image with random guess\n",
        "            noise = np.random.normal(size=self.content_shape, scale=np.std(self.content) * 0.1)  # useless\n",
        "            if init_image == 'random':\n",
        "                init_image = tf.random_normal(self.content_shape)\n",
        "            elif init_image == 'content':\n",
        "                init_image = np.reshape(np.array(self.content - self.vgg.mean_pix), self.content_shape)\n",
        "            mixed_image = tf.Variable(init_image, dtype=tf.float32)\n",
        "            mixed_net = self.vgg.load_net(mixed_image)\n",
        "\n",
        "            # calculate loss\n",
        "            loss_content = self.calculate_loss_content(mixed_net)\n",
        "            loss_style = self.calculate_loss_style(mixed_net)\n",
        "            loss_variation = self.calculate_loss_variation(mixed_image)\n",
        "            loss_total = loss_content + loss_style + loss_variation\n",
        "\n",
        "            # summary statistics\n",
        "            tf.summary.scalar('loss_content', loss_content)\n",
        "            tf.summary.scalar('loss_style', loss_style)\n",
        "            tf.summary.scalar('loss_variation', loss_variation)\n",
        "            tf.summary.scalar('loss_total', loss_total)\n",
        "            summary_loss = tf.summary.merge_all()\n",
        "\n",
        "            # initialize optimization\n",
        "            train_step = tf.train.AdamOptimizer(learning_rate, beta1, beta2, epsilon).minimize(loss_total)\n",
        "\n",
        "            with tf.Session() as sess:\n",
        "                summary_writer = tf.summary.FileWriter(PATH + 'logs', sess.graph)\n",
        "                sess.run(tf.global_variables_initializer())\n",
        "\n",
        "                for i in range(max_iteration):\n",
        "                    train_step.run()\n",
        "                    summary = sess.run(summary_loss)\n",
        "                    summary_writer.add_summary(summary, i)\n",
        "                    # save image\n",
        "                    if (check_point and ((i + 1) % check_point) == 0) or i == max_iteration - 1:\n",
        "                        image_out = mixed_image.eval()\n",
        "                        image_out = image_out.reshape(self.content_shape[1:]) + self.vgg.mean_pix\n",
        "                        print('iter: {}, loss total: {}, loss content: {}, loss style: {}, loss variation: {}'.format(\n",
        "                            i + 1, loss_total.eval(), loss_content.eval(), loss_style.eval(), loss_variation.eval()\n",
        "                        ))\n",
        "                        yield i, image_out\n",
        "\n",
        "    def calculate_loss_content(self, mixed_net):\n",
        "        losses = []\n",
        "        for layer_name in self.content_layer_weights:\n",
        "            losses += [self.content_layer_weights[layer_name] * 2 * tf.nn.l2_loss(\n",
        "                mixed_net[layer_name] - self.content_features[layer_name]) / self.content_features[\n",
        "                           layer_name].size]  # TODO: find out why divide by the size\n",
        "        return self.content_weight * reduce(tf.add, losses)\n",
        "\n",
        "    def calculate_loss_style(self, mixed_net):\n",
        "        losses = []\n",
        "        for layer_name in self.style_layer_weights:\n",
        "            _, height, width, channel = mixed_net[layer_name].get_shape()\n",
        "            size = height.value * width.value * channel.value\n",
        "            mixed_features = tf.reshape(mixed_net[layer_name], (-1, channel.value))\n",
        "            mixed_gram = tf.matmul(tf.transpose(mixed_features),\n",
        "                                   mixed_features) / size  # TODO: find out why divide by the size\n",
        "            losses += [self.style_layer_weights[layer_name] * 2 * tf.nn.l2_loss(\n",
        "                mixed_gram - self.style_features[\n",
        "                    layer_name]) / self.style_features[layer_name].size]  # TODO: find out why divide by the size\n",
        "        return self.style_weight * reduce(tf.add, losses)\n",
        "\n",
        "    def calculate_loss_variation(self, mixed_image):\n",
        "        height_size = np.prod([dim.value for dim in mixed_image[:, 1:, :, :].get_shape()])\n",
        "        width_size = np.prod([dim.value for dim in mixed_image[:, :, 1:, :].get_shape()])\n",
        "        loss = 2 * (tf.nn.l2_loss(\n",
        "            mixed_image[:, 1:, :, :] - mixed_image[:, :mixed_image.shape[1] - 1, :, :]) / height_size + tf.nn.l2_loss(\n",
        "            mixed_image[:, :, 1:, :] - mixed_image[:, :, :mixed_image.shape[2] - 1, :]) / width_size)\n",
        "        return self.variation_weight * loss\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q4_KvOV1cQ-F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### main function"
      ]
    },
    {
      "metadata": {
        "id": "yqa12dkmcO_Y",
        "colab_type": "code",
        "outputId": "e7a50001-ec14-479b-c707-7d2b70c21717",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    style_transfer(content_image_path=CONTENT_IMAGE_PATH,\n",
        "                   style_image_path=STYLE_IMAGE_PATH,\n",
        "                   mixed_image_path=MIXED_IMAGE_PATH,\n",
        "                   content_weight=CONTENT_WEIGHT,\n",
        "                   style_weight=STYLE_WEIGHT,\n",
        "                   variation_weight=VARIATION_WEIGHT,\n",
        "                   pooling=POOLING,\n",
        "                   learning_rate=LEARNING_RATE,\n",
        "                   beta1=BETA1,\n",
        "                   beta2=BETA2,\n",
        "                   epsilon=EPSILON,\n",
        "                   max_iteration=MAX_ITERATION,\n",
        "                   check_point=CHECK_POINT)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 95, 71, 512)\n",
            "iter: 10, loss total: 7170287.5, loss content: 2416433.5, loss style: 4494966.5, loss variation: 258887.6875\n",
            "Time elapsed: 36 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ns6gbBzHcSq5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}