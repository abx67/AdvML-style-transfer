{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "feavisual.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "CPHZv5LZGGMY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cPickle\n",
        "from tensorflow.python.platform import gfile\n",
        "from random import randint\n",
        "import os\n",
        "from scipy.misc import imsave\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QTdLqT5sGMRH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def unpickle(file):\n",
        "  fo = open(file, 'rb')\n",
        "  dict = cPickle.load(fo)\n",
        "  fo.close()\n",
        "  return dict\n",
        "\n",
        "def initWeight(shape):\n",
        "    weights = tf.truncated_normal(shape,stddev=0.1)\n",
        "    return tf.Variable(weights)\n",
        "\n",
        "# start with 0.1 so reLu isnt always 0\n",
        "def initBias(shape):\n",
        "    bias = tf.constant(0.1,shape=shape)\n",
        "    return tf.Variable(bias)\n",
        "\n",
        "# the convolution with padding of 1 on each side, and moves by 1.\n",
        "def conv2d(x,W):\n",
        "    return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding=\"SAME\")\n",
        "\n",
        "# max pooling basically shrinks it by 2x, taking the highest value on each feature.\n",
        "def maxPool2d(x):\n",
        "    return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding=\"SAME\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "STb0GarPGPY9",
        "colab_type": "code",
        "outputId": "a8d4129c-dc88-4d20-a63f-459caec254d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "batchsize = 50;\n",
        "imagesize = 32;\n",
        "colors = 3;\n",
        "\n",
        "sess = tf.InteractiveSession()\n",
        "\n",
        "img = tf.placeholder(\"float\",shape=[None,imagesize,imagesize,colors])\n",
        "lbl = tf.placeholder(\"float\",shape=[None,10])\n",
        "# for each 5x5 area, check for 32 features over 3 color channels\n",
        "wConv1 = initWeight([5,5,colors,32])\n",
        "bConv1 = initBias([32])\n",
        "# move the conv filter over the picture\n",
        "conv1 = conv2d(img,wConv1)\n",
        "# adds bias\n",
        "bias1 = conv1 + bConv1\n",
        "# relu = max(0,x), adds nonlinearality\n",
        "relu1 = tf.nn.relu(bias1)\n",
        "# maxpool to 16x16\n",
        "pool1 = maxPool2d(relu1)\n",
        "# second conv layer, takes a 16x16 with 32 layers, turns to 8x8 with 64 layers\n",
        "wConv2 = initWeight([5,5,32,64])\n",
        "bConv2 = initBias([64])\n",
        "conv2 = conv2d(pool1,wConv2)\n",
        "bias2 = conv2 + bConv2\n",
        "relu2 = tf.nn.relu(bias2)\n",
        "pool2 = maxPool2d(relu2)\n",
        "# fully-connected is just a regular neural net: 8*8*64 for each training data\n",
        "wFc1 = initWeight([(imagesize/4) * (imagesize/4) * 64, 1024])\n",
        "bFc1 = initBias([1024])\n",
        "# reduce dimensions to flatten\n",
        "pool2flat = tf.reshape(pool2, [-1, (imagesize/4) * (imagesize/4) *64])\n",
        "# 128 training set by 2304 data points\n",
        "fc1 = tf.matmul(pool2flat,wFc1) + bFc1;\n",
        "relu3 = tf.nn.relu(fc1);\n",
        "# dropout removes duplicate weights\n",
        "keepProb = tf.placeholder(\"float\");\n",
        "drop = tf.nn.dropout(relu3,keepProb);\n",
        "wFc2 = initWeight([1024,10]);\n",
        "bFc2 = initWeight([10]);\n",
        "# softmax converts individual probabilities to percentages\n",
        "guesses = tf.nn.softmax(tf.matmul(drop, wFc2) + bFc2);\n",
        "# how wrong it is\n",
        "cross_entropy = -tf.reduce_sum(lbl*tf.log(guesses + 1e-9));\n",
        "# theres a lot of tensorflow optimizers such as gradient descent\n",
        "# adam is one of them\n",
        "optimizer = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy);\n",
        "# array of bools, checking if each guess was correct\n",
        "correct_prediction = tf.equal(tf.argmax(guesses,1), tf.argmax(lbl,1));\n",
        "# represent the correctness as a float [1,1,0,1] -> 0.75\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"));\n",
        "\n",
        "\n",
        "sess.run(tf.initialize_all_variables());"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/util/tf_should_use.py:189: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
            "Instructions for updating:\n",
            "Use `tf.global_variables_initializer` instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "g8UomSbKIrqO",
        "colab_type": "code",
        "outputId": "0f17704b-5bee-4c0e-9115-840571dc3e3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "cell_type": "code",
      "source": [
        "cifar_url = \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
        "cifar_name = \"cifar-10-python.tar.gz\"\n",
        "if not os.path.exists(cifar_name):\n",
        "  !curl -O $cifar_url\n",
        "  !tar -zxvf $cifar_name\n",
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  162M  100  162M    0     0  8349k      0  0:00:19  0:00:19 --:--:-- 6453k\n",
            "cifar-10-batches-py/\n",
            "cifar-10-batches-py/data_batch_4\n",
            "cifar-10-batches-py/readme.html\n",
            "cifar-10-batches-py/test_batch\n",
            "cifar-10-batches-py/data_batch_3\n",
            "cifar-10-batches-py/batches.meta\n",
            "cifar-10-batches-py/data_batch_2\n",
            "cifar-10-batches-py/data_batch_5\n",
            "cifar-10-batches-py/data_batch_1\n",
            " adc.json\t\t\t\t      sample_data\n",
            " cifar-10-batches-py\t\t\t      tumor_078_mask.tif\n",
            " cifar-10-python.tar.gz\t\t\t      tumor_078.tif\n",
            " img\t\t\t\t\t      tumor_091_mask.tif\n",
            "'open?id=1bKu35C-S7vfT3HRTalObSZdavAOvzBQg'   tumor_091.tif\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "a45IKxDJIqzd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch = unpickle(\"cifar-10-batches-py/data_batch_1\")\n",
        "\n",
        "validationData = batch[\"data\"][555:batchsize+555]\n",
        "validationRawLabel = batch[\"labels\"][555:batchsize+555]\n",
        "validationLabel = np.zeros((batchsize,10))\n",
        "validationLabel[np.arange(batchsize),validationRawLabel] = 1\n",
        "validationData = validationData/255.0\n",
        "validationData = np.reshape(validationData,[-1,3,32,32])\n",
        "validationData = np.swapaxes(validationData,1,3)\n",
        "\n",
        "if not os.path.exists(\"./training\"): \n",
        "  os.mkdir(\"./training\")\n",
        "  \n",
        "saver = tf.train.Saver()\n",
        "# saver.restore(sess, tf.train.latest_checkpoint(\"./training\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IWUVfkECFiNx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# train for 20000\n",
        "# print mnistbatch[0].shape\n",
        "def train():\n",
        "    for i in range(20000):\n",
        "        randomint = randint(0,10000 - batchsize - 1)\n",
        "        trainingData = batch[\"data\"][randomint:batchsize+randomint]\n",
        "        rawlabel = batch[\"labels\"][randomint:batchsize+randomint]\n",
        "        trainingLabel = np.zeros((batchsize,10))\n",
        "        trainingLabel[np.arange(batchsize),rawlabel] = 1\n",
        "        trainingData = trainingData/255.0\n",
        "        trainingData = np.reshape(trainingData,[-1,3,32,32])\n",
        "        trainingData = np.swapaxes(trainingData,1,3)\n",
        "\n",
        "        if i%10 == 0:\n",
        "            train_accuracy = accuracy.eval(feed_dict={\n",
        "            img: validationData, lbl: validationLabel, keepProb: 1.0})\n",
        "            print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
        "\n",
        "            if i%50 == 0:\n",
        "                saver.save(sess, os.getcwd()+\"/training/train\", global_step=i)\n",
        "\n",
        "        optimizer.run(feed_dict={img: trainingData, lbl: trainingLabel, keepProb: 0.5})\n",
        "        print i\n",
        "\n",
        "def unpool(value, name='unpool'):\n",
        "    \"\"\"N-dimensional version of the unpooling operation from\n",
        "    https://www.robots.ox.ac.uk/~vgg/rg/papers/Dosovitskiy_Learning_to_Generate_2015_CVPR_paper.pdf\n",
        "\n",
        "    :param value: A Tensor of shape [b, d0, d1, ..., dn, ch]\n",
        "    :return: A Tensor of shape [b, 2*d0, 2*d1, ..., 2*dn, ch]\n",
        "    \"\"\"\n",
        "    with tf.name_scope(name) as scope:\n",
        "        sh = value.get_shape().as_list()\n",
        "        dim = len(sh[1:-1])\n",
        "        out = (tf.reshape(value, [-1] + sh[-dim:]))\n",
        "        for i in range(dim, 0, -1):\n",
        "            out = tf.concat(i, [out, out])\n",
        "        out_size = [-1] + [s * 2 for s in sh[1:-1]] + [sh[-1]]\n",
        "        out = tf.reshape(out, out_size, name=scope)\n",
        "    return out\n",
        "\n",
        "def display():\n",
        "    print \"displaying\"\n",
        "\n",
        "    batchsizeFeatures = 50\n",
        "    imageIndex = 56\n",
        "\n",
        "    inputImage = batch[\"data\"][imageIndex:imageIndex+batchsizeFeatures]\n",
        "    inputImage = inputImage/255.0\n",
        "    inputImage = np.reshape(inputImage,[-1,3,32,32])\n",
        "    inputImage = np.swapaxes(inputImage,1,3)\n",
        "\n",
        "    inputLabel = np.zeros((batchsize,10))\n",
        "    inputLabel[np.arange(1),batch[\"labels\"][imageIndex:imageIndex+batchsizeFeatures]] = 1;\n",
        "    # inputLabel = batch[\"labels\"][54]\n",
        "\n",
        "\n",
        "    # prints a given image\n",
        "\n",
        "\n",
        "    # saves pixel-representations of features from Conv layer 1\n",
        "    featuresReLu1 = tf.placeholder(\"float\",[None,32,32,32])\n",
        "    unReLu = tf.nn.relu(featuresReLu1)\n",
        "    unBias = unReLu\n",
        "    unConv = tf.nn.conv2d_transpose(unBias, wConv1, output_shape=[batchsizeFeatures,imagesize,imagesize,colors] , strides=[1,1,1,1], padding=\"SAME\")\n",
        "    activations1 = relu1.eval(feed_dict={img: inputImage, lbl: inputLabel, keepProb: 1.0})\n",
        "    print np.shape(activations1)\n",
        "\n",
        "    # display features\n",
        "    for i in xrange(32):\n",
        "        isolated = activations1.copy()\n",
        "        isolated[:,:,:,:i] = 0\n",
        "        isolated[:,:,:,i+1:] = 0\n",
        "        print np.shape(isolated)\n",
        "        totals = np.sum(isolated,axis=(1,2,3))\n",
        "        best = np.argmin(totals,axis=0)\n",
        "        print best\n",
        "        pixelactive = unConv.eval(feed_dict={featuresReLu1: isolated})\n",
        "        # totals = np.sum(pixelactive,axis=(1,2,3))\n",
        "        # best = np.argmax(totals,axis=0)\n",
        "        # best = 0\n",
        "        saveImage(pixelactive[best],\"activ\"+str(i)+\".png\")\n",
        "        saveImage(inputImage[best],\"activ\"+str(i)+\"-base.png\")\n",
        "\n",
        "    # display same feature for many images\n",
        "    # for i in xrange(batchsizeFeatures):\n",
        "    #     isolated = activations1.copy()\n",
        "    #     isolated[:,:,:,:6] = 0\n",
        "    #     isolated[:,:,:,7:] = 0\n",
        "    #     pixelactive = unConv.eval(feed_dict={featuresReLu1: isolated})\n",
        "    #     totals = np.sum(pixelactive,axis=(1,2,3))\n",
        "    #     best = np.argmax(totals,axis=0)\n",
        "    #     saveImage(pixelactive[i],\"activ\"+str(i)+\".png\")\n",
        "    #     saveImage(inputImage[i],\"activ\"+str(i)+\"-base.png\")\n",
        "\n",
        "\n",
        "\n",
        "    # saves pixel-representations of features from Conv layer 2\n",
        "    featuresReLu2 = tf.placeholder(\"float\",[None,16,16,64])\n",
        "    unReLu2 = tf.nn.relu(featuresReLu2)\n",
        "    unBias2 = unReLu2\n",
        "    unConv2 = tf.nn.conv2d_transpose(unBias2, wConv2, output_shape=[batchsizeFeatures,imagesize/2,imagesize/2,32] , strides=[1,1,1,1], padding=\"SAME\")\n",
        "    unPool = unpool(unConv2)\n",
        "    unReLu = tf.nn.relu(unPool)\n",
        "    unBias = unReLu\n",
        "    unConv = tf.nn.conv2d_transpose(unBias, wConv1, output_shape=[batchsizeFeatures,imagesize,imagesize,colors] , strides=[1,1,1,1], padding=\"SAME\")\n",
        "    activations1 = relu2.eval(feed_dict={img: inputImage, lbl: inputLabel, keepProb: 1.0})\n",
        "    print np.shape(activations1)\n",
        "\n",
        "    # display features\n",
        "    # for i in xrange(64):\n",
        "    #     isolated = activations1.copy()\n",
        "    #     isolated[:,:,:,:i] = 0\n",
        "    #     isolated[:,:,:,i+1:] = 0\n",
        "    #     pixelactive = unConv.eval(feed_dict={featuresReLu2: isolated})\n",
        "    #     # totals = np.sum(pixelactive,axis=(1,2,3))\n",
        "    #     # best = np.argmax(totals,axis=0)\n",
        "    #     best = 0\n",
        "    #     saveImage(pixelactive[best],\"activ\"+str(i)+\".png\")\n",
        "    #     saveImage(inputImage[best],\"activ\"+str(i)+\"-base.png\")\n",
        "\n",
        "\n",
        "    # display same feature for many images\n",
        "    # for i in xrange(batchsizeFeatures):\n",
        "    #     isolated = activations1.copy()\n",
        "    #     isolated[:,:,:,:8] = 0\n",
        "    #     isolated[:,:,:,9:] = 0\n",
        "    #     pixelactive = unConv.eval(feed_dict={featuresReLu2: isolated})\n",
        "    #     totals = np.sum(pixelactive,axis=(1,2,3))\n",
        "    #     # best = np.argmax(totals,axis=0)\n",
        "    #     # best = 0\n",
        "    #     saveImage(pixelactive[i],\"activ\"+str(i)+\".png\")\n",
        "    #     saveImage(inputImage[i],\"activ\"+str(i)+\"-base.png\")\n",
        "\n",
        "\n",
        "\n",
        "def saveImage(inputImage, name):\n",
        "    # red = inputImage[:1024]\n",
        "    # green = inputImage[1024:2048]\n",
        "    # blue = inputImage[2048:]\n",
        "    # formatted = np.zeros([3,32,32])\n",
        "    # formatted[0] = np.reshape(red,[32,32])\n",
        "    # formatted[1] = np.reshape(green,[32,32])\n",
        "    # formatted[2] = np.reshape(blue,[32,32])\n",
        "    # final = np.swapaxes(formatted,0,2)/255;\n",
        "    final = inputImage\n",
        "    final = np.rot90(np.rot90(np.rot90(final)))\n",
        "    imsave(name,final)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yOKNaOPtGWfF",
        "colab_type": "code",
        "outputId": "d8dbc64e-b374-46ee-9a62-4f1e47e37816",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2088
        }
      },
      "cell_type": "code",
      "source": [
        "def main(argv=None):\n",
        "    display()\n",
        "    # train()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    tf.app.run()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "displaying\n",
            "(50, 32, 32, 32)\n",
            "(50, 32, 32, 32)\n",
            "29\n",
            "(50, 32, 32, 32)\n",
            "21\n",
            "(50, 32, 32, 32)\n",
            "7\n",
            "(50, 32, 32, 32)\n",
            "6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:146: DeprecationWarning: `imsave` is deprecated!\n",
            "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``imageio.imwrite`` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(50, 32, 32, 32)\n",
            "39\n",
            "(50, 32, 32, 32)\n",
            "29\n",
            "(50, 32, 32, 32)\n",
            "48\n",
            "(50, 32, 32, 32)\n",
            "6\n",
            "(50, 32, 32, 32)\n",
            "24\n",
            "(50, 32, 32, 32)\n",
            "2\n",
            "(50, 32, 32, 32)\n",
            "6\n",
            "(50, 32, 32, 32)\n",
            "14\n",
            "(50, 32, 32, 32)\n",
            "6\n",
            "(50, 32, 32, 32)\n",
            "48\n",
            "(50, 32, 32, 32)\n",
            "29\n",
            "(50, 32, 32, 32)\n",
            "39\n",
            "(50, 32, 32, 32)\n",
            "6\n",
            "(50, 32, 32, 32)\n",
            "24\n",
            "(50, 32, 32, 32)\n",
            "29\n",
            "(50, 32, 32, 32)\n",
            "2\n",
            "(50, 32, 32, 32)\n",
            "2\n",
            "(50, 32, 32, 32)\n",
            "29\n",
            "(50, 32, 32, 32)\n",
            "43\n",
            "(50, 32, 32, 32)\n",
            "11\n",
            "(50, 32, 32, 32)\n",
            "29\n",
            "(50, 32, 32, 32)\n",
            "23\n",
            "(50, 32, 32, 32)\n",
            "2\n",
            "(50, 32, 32, 32)\n",
            "29\n",
            "(50, 32, 32, 32)\n",
            "43\n",
            "(50, 32, 32, 32)\n",
            "13\n",
            "(50, 32, 32, 32)\n",
            "43\n",
            "(50, 32, 32, 32)\n",
            "6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-b241ee30c7e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m    123\u001b[0m   \u001b[0;31m# Call the main function, passing through any arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m   \u001b[0;31m# to the final program.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m   \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-b241ee30c7e5>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(argv)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;31m# train()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-bf9f76bed9de>\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m()\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0munBias2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munReLu2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0munConv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_transpose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munBias2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwConv2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatchsizeFeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimagesize\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimagesize\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"SAME\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m     \u001b[0munPool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munConv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m     \u001b[0munReLu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munPool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0munBias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munReLu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-bf9f76bed9de>\u001b[0m in \u001b[0;36munpool\u001b[0;34m(value, name)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mout_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.pyc\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1120\u001b[0m           \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"concat_dim\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m           \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_is_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m               tensor_shape.scalar())\n\u001b[0m\u001b[1;32m   1123\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/tensor_shape.pyc\u001b[0m in \u001b[0;36massert_is_compatible_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    846\u001b[0m     \"\"\"\n\u001b[1;32m    847\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shapes %s and %s are incompatible\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mmost_specific_compatible_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Shapes (2, 800, 16, 32) and () are incompatible"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "p7IU36FRKs-_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}